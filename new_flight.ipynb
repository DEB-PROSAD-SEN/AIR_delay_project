{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d3827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU detected! Using GPU acceleration for XGBoost & CatBoost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_5768\\734715023.py:35: DtypeWarning: Columns (11,13,86,93,94,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"D:\\flight delay\\flight_data_2018_2024.csv\\flight_data_2018_2024.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape: (582425, 120)\n",
      "Using target column: DepDelay\n",
      "Categorical columns to label-encode: ['FlightDate', 'Marketing_Airline_Network', 'Operated_or_Branded_Code_Share_Partners', 'IATA_Code_Marketing_Airline', 'Originally_Scheduled_Code_Share_Airline', 'IATA_Code_Originally_Scheduled_Code_Share_Airline', 'Operating_Airline ', 'IATA_Code_Operating_Airline', 'Tail_Number', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateName', 'Dest', 'DestCityName', 'DestState', 'DestStateName', 'DepTimeBlk', 'ArrTimeBlk', 'CancellationCode', 'Div1Airport', 'Div1TailNum', 'Div2Airport', 'Div2TailNum', 'Div3Airport', 'Div3TailNum', 'Duplicate']\n",
      "Numeric columns to standardize: ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'DOT_ID_Marketing_Airline', 'Flight_Number_Marketing_Airline', 'DOT_ID_Originally_Scheduled_Code_Share_Airline', 'Flight_Num_Originally_Scheduled_Code_Share_Airline', 'DOT_ID_Operating_Airline', 'Flight_Number_Operating_Airline', 'OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'OriginStateFips', 'OriginWac', 'DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'DestStateFips', 'DestWac', 'CRSDepTime', 'DepTime', 'DepDelayMinutes', 'DepDel15', 'DepartureDelayGroups', 'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDelay', 'ArrDelayMinutes', 'ArrDel15', 'ArrivalDelayGroups', 'Cancelled', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Flights', 'Distance', 'DistanceGroup', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime', 'DivAirportLandings', 'DivReachedDest', 'DivActualElapsedTime', 'DivArrDelay', 'DivDistance', 'Div1AirportID', 'Div1AirportSeqID', 'Div1WheelsOn', 'Div1TotalGTime', 'Div1LongestGTime', 'Div1WheelsOff', 'Div2AirportID', 'Div2AirportSeqID', 'Div2WheelsOn', 'Div2TotalGTime', 'Div2LongestGTime', 'Div2WheelsOff', 'Div3AirportID', 'Div3AirportSeqID', 'Div3WheelsOn', 'Div3TotalGTime', 'Div3LongestGTime', 'Div3WheelsOff', 'Div4Airport', 'Div4AirportID', 'Div4AirportSeqID', 'Div4WheelsOn', 'Div4TotalGTime', 'Div4LongestGTime', 'Div4WheelsOff', 'Div4TailNum', 'Div5Airport', 'Div5AirportID', 'Div5AirportSeqID', 'Div5WheelsOn', 'Div5TotalGTime', 'Div5LongestGTime', 'Div5WheelsOff', 'Div5TailNum', 'Unnamed: 119']\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Global configs\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Detect GPU availability\n",
    "# ----------------------------\n",
    "def has_gpu():\n",
    "    try:\n",
    "        subprocess.run([\"nvidia-smi\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "        print(\"✅ GPU detected! Using GPU acceleration for XGBoost & CatBoost.\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        print(\"⚠️ No GPU detected. Running on CPU.\")\n",
    "        return False\n",
    "\n",
    "GPU_AVAILABLE = has_gpu()\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load dataset\n",
    "# ----------------------------\n",
    "df = pd.read_csv(r\"D:\\flight delay\\flight_data_2018_2024.csv\\flight_data_2018_2024.csv\")\n",
    "print(f'Loaded data with shape: {df.shape}')\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Target selection\n",
    "# ----------------------------\n",
    "def choose_target(df):\n",
    "    for col in ['DepDelay', 'ArrDelay', 'Delay', 'DelayMinutes']:\n",
    "        if col in df.columns:\n",
    "            print(f\"Using target column: {col}\")\n",
    "            return col\n",
    "    delay_cols = [c for c in df.columns if 'delay' in c.lower() and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if delay_cols:\n",
    "        print(f\"Using detected numeric delay column: {delay_cols[0]}\")\n",
    "        return delay_cols[0]\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not numeric_cols:\n",
    "        raise ValueError('No numeric columns found to use as a regression target.')\n",
    "    print(f\"No explicit delay column found. Falling back to first numeric column: {numeric_cols[0]}\")\n",
    "    return numeric_cols[0]\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Preprocessing\n",
    "# ----------------------------\n",
    "def preprocess(df, target_col, keep_cols=None):\n",
    "    df = df[~df[target_col].isna()].reset_index(drop=True)\n",
    "    if keep_cols is None:\n",
    "        keep_cols = ['CancellationCode', 'Org_Airport', 'Dest_Airport']\n",
    "    keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col].astype(float)\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for c in keep_cols:\n",
    "        if c in X.columns and c not in cat_cols:\n",
    "            cat_cols.append(c)\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    print(f'Categorical columns to label-encode: {cat_cols}')\n",
    "    print(f'Numeric columns to standardize: {num_cols}')\n",
    "    return X, y, cat_cols, num_cols\n",
    "\n",
    "def fit_label_encoders(X_train, X_valid, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = X_train[col].fillna('___MISSING___').astype(str)\n",
    "        X_valid[col] = X_valid[col].fillna('___MISSING___').astype(str)\n",
    "        le.fit(X_train[col])\n",
    "        X_train[col] = le.transform(X_train[col])\n",
    "        valid_mapped = []\n",
    "        classes = set(le.classes_)\n",
    "        unk_code = len(le.classes_)\n",
    "        for v in X_valid[col]:\n",
    "            if v in classes:\n",
    "                valid_mapped.append(int(np.where(le.classes_ == v)[0][0]))\n",
    "            else:\n",
    "                valid_mapped.append(unk_code)\n",
    "        X_valid[col] = valid_mapped\n",
    "    return X_train, X_valid\n",
    "\n",
    "def standardize_numeric(X_train, X_valid, num_cols):\n",
    "    scaler = StandardScaler()\n",
    "    if num_cols:\n",
    "        X_train[num_cols] = scaler.fit_transform(X_train[num_cols].fillna(0))\n",
    "        X_valid[num_cols] = scaler.transform(X_valid[num_cols].fillna(0))\n",
    "    return X_train, X_valid\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Parameter grids\n",
    "# ----------------------------\n",
    "def get_param_distributions():\n",
    "    xgb_dist = {\n",
    "        'n_estimators': [100, 200, 400],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "    cat_dist = {\n",
    "        'iterations': [200, 400],\n",
    "        'depth': [4, 6, 10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1]\n",
    "    }\n",
    "    return xgb_dist, cat_dist\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Tuning function\n",
    "# ----------------------------\n",
    "def tune_model(estimator, param_distributions, X, y, n_iter=8, cv=3):\n",
    "    cv = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator,\n",
    "        param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=N_JOBS,\n",
    "        cv=cv,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=1\n",
    "    )\n",
    "    rs.fit(X, y)\n",
    "    print(f'Best score: {rs.best_score_} | Best params: {rs.best_params_}')\n",
    "    return rs.best_estimator_\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Main pipeline\n",
    "# ----------------------------\n",
    "target_col = choose_target(df)\n",
    "X, y, cat_cols, num_cols = preprocess(df, target_col)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train, X_test = fit_label_encoders(X_train.copy(), X_test.copy(), cat_cols)\n",
    "X_train, X_test = standardize_numeric(X_train, X_test, num_cols)\n",
    "\n",
    "xgb_dist, cat_dist = get_param_distributions()\n",
    "\n",
    "# XGBoost (GPU if available)\n",
    "xgb_best = tune_model(\n",
    "    XGBRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1,\n",
    "        objective='reg:squarederror',\n",
    "        verbosity=0,\n",
    "        tree_method='gpu_hist' if GPU_AVAILABLE else 'hist',\n",
    "        predictor='gpu_predictor' if GPU_AVAILABLE else 'auto'\n",
    "    ),\n",
    "    xgb_dist, X_train, y_train, n_iter=8\n",
    ")\n",
    "\n",
    "# CatBoost (GPU if available)\n",
    "cat_best = tune_model(\n",
    "    CatBoostRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=0,\n",
    "        task_type='GPU' if GPU_AVAILABLE else 'CPU',\n",
    "        devices='0' if GPU_AVAILABLE else None\n",
    "    ),\n",
    "    cat_dist, X_train, y_train, n_iter=8\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Stacking Ensemble\n",
    "# ----------------------------\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('xgb', xgb_best), ('cat', cat_best)],\n",
    "    final_estimator=RidgeCV(),\n",
    "    n_jobs=N_JOBS\n",
    ")\n",
    "\n",
    "print('\\nTraining stacking regressor...')\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "preds = stack.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print('\\nTest set evaluation:')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'R2: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675b6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bcaa296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU detected! Using GPU acceleration for XGBoost & CatBoost.\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Detect GPU availability\n",
    "# ----------------------------\n",
    "def has_gpu():\n",
    "    try:\n",
    "        subprocess.run([\"nvidia-smi\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "        print(\"✅ GPU detected! Using GPU acceleration for XGBoost & CatBoost.\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        print(\"⚠️ No GPU detected. Running on CPU.\")\n",
    "        return False\n",
    "\n",
    "GPU_AVAILABLE = has_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29826aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3716\\3250364045.py:1: DtypeWarning: Columns (11,13,86,93,94,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"D:\\flight delay\\flight_data_2018_2024.csv\\flight_data_2018_2024.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape: (582425, 120)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\flight delay\\flight_data_2018_2024.csv\\flight_data_2018_2024.csv\")\n",
    "print(f'Loaded data with shape: {df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e89558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_target(df):\n",
    "    for col in ['DepDelay', 'ArrDelay', 'Delay', 'DelayMinutes']:\n",
    "        if col in df.columns:\n",
    "            print(f\"Using target column: {col}\")\n",
    "            return col\n",
    "    delay_cols = [c for c in df.columns if 'delay' in c.lower() and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if delay_cols:\n",
    "        print(f\"Using detected numeric delay column: {delay_cols[0]}\")\n",
    "        return delay_cols[0]\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not numeric_cols:\n",
    "        raise ValueError('No numeric columns found to use as a regression target.')\n",
    "    print(f\"No explicit delay column found. Falling back to first numeric column: {numeric_cols[0]}\")\n",
    "    return numeric_cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b51dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, target_col, keep_cols=None):\n",
    "    df = df[~df[target_col].isna()].reset_index(drop=True)\n",
    "    if keep_cols is None:\n",
    "        keep_cols = ['CancellationCode', 'Org_Airport', 'Dest_Airport']\n",
    "    keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col].astype(float)\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for c in keep_cols:\n",
    "        if c in X.columns and c not in cat_cols:\n",
    "            cat_cols.append(c)\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    print(f'Categorical columns to label-encode: {cat_cols}')\n",
    "    print(f'Numeric columns to standardize: {num_cols}')\n",
    "    return X, y, cat_cols, num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7ee97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_label_encoders(X_train, X_valid, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = X_train[col].fillna('___MISSING___').astype(str)\n",
    "        X_valid[col] = X_valid[col].fillna('___MISSING___').astype(str)\n",
    "        le.fit(X_train[col])\n",
    "        X_train[col] = le.transform(X_train[col])\n",
    "        valid_mapped = []\n",
    "        classes = set(le.classes_)\n",
    "        unk_code = len(le.classes_)\n",
    "        for v in X_valid[col]:\n",
    "            if v in classes:\n",
    "                valid_mapped.append(int(np.where(le.classes_ == v)[0][0]))\n",
    "            else:\n",
    "                valid_mapped.append(unk_code)\n",
    "        X_valid[col] = valid_mapped\n",
    "    return X_train, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d1ba1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_numeric(X_train, X_valid, num_cols):\n",
    "    scaler = StandardScaler()\n",
    "    if num_cols:\n",
    "        X_train[num_cols] = scaler.fit_transform(X_train[num_cols].fillna(0))\n",
    "        X_valid[num_cols] = scaler.transform(X_valid[num_cols].fillna(0))\n",
    "    return X_train, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c85137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_distributions():\n",
    "    xgb_dist = {\n",
    "        'n_estimators': [100, 200, 400],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "    cat_dist = {\n",
    "        'iterations': [200, 400],\n",
    "        'depth': [4, 6, 10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1]\n",
    "    }\n",
    "    return xgb_dist, cat_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ba7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(estimator, param_distributions, X, y, n_iter=8, cv=3):\n",
    "    cv = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator,\n",
    "        param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=N_JOBS,\n",
    "        cv=cv,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=1\n",
    "    )\n",
    "    rs.fit(X, y)\n",
    "    print(f'Best score: {rs.best_score_} | Best params: {rs.best_params_}')\n",
    "    return rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21312eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using target column: DepDelay\n",
      "Categorical columns to label-encode: ['FlightDate', 'Marketing_Airline_Network', 'Operated_or_Branded_Code_Share_Partners', 'IATA_Code_Marketing_Airline', 'Originally_Scheduled_Code_Share_Airline', 'IATA_Code_Originally_Scheduled_Code_Share_Airline', 'Operating_Airline ', 'IATA_Code_Operating_Airline', 'Tail_Number', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateName', 'Dest', 'DestCityName', 'DestState', 'DestStateName', 'DepTimeBlk', 'ArrTimeBlk', 'CancellationCode', 'Div1Airport', 'Div1TailNum', 'Div2Airport', 'Div2TailNum', 'Div3Airport', 'Div3TailNum', 'Duplicate']\n",
      "Numeric columns to standardize: ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'DOT_ID_Marketing_Airline', 'Flight_Number_Marketing_Airline', 'DOT_ID_Originally_Scheduled_Code_Share_Airline', 'Flight_Num_Originally_Scheduled_Code_Share_Airline', 'DOT_ID_Operating_Airline', 'Flight_Number_Operating_Airline', 'OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'OriginStateFips', 'OriginWac', 'DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'DestStateFips', 'DestWac', 'CRSDepTime', 'DepTime', 'DepDelayMinutes', 'DepDel15', 'DepartureDelayGroups', 'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDelay', 'ArrDelayMinutes', 'ArrDel15', 'ArrivalDelayGroups', 'Cancelled', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Flights', 'Distance', 'DistanceGroup', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime', 'DivAirportLandings', 'DivReachedDest', 'DivActualElapsedTime', 'DivArrDelay', 'DivDistance', 'Div1AirportID', 'Div1AirportSeqID', 'Div1WheelsOn', 'Div1TotalGTime', 'Div1LongestGTime', 'Div1WheelsOff', 'Div2AirportID', 'Div2AirportSeqID', 'Div2WheelsOn', 'Div2TotalGTime', 'Div2LongestGTime', 'Div2WheelsOff', 'Div3AirportID', 'Div3AirportSeqID', 'Div3WheelsOn', 'Div3TotalGTime', 'Div3LongestGTime', 'Div3WheelsOff', 'Div4Airport', 'Div4AirportID', 'Div4AirportSeqID', 'Div4WheelsOn', 'Div4TotalGTime', 'Div4LongestGTime', 'Div4WheelsOff', 'Div4TailNum', 'Div5Airport', 'Div5AirportID', 'Div5AirportSeqID', 'Div5WheelsOn', 'Div5TotalGTime', 'Div5LongestGTime', 'Div5WheelsOff', 'Div5TailNum', 'Unnamed: 119']\n"
     ]
    }
   ],
   "source": [
    "target_col = choose_target(df)\n",
    "X, y, cat_cols, num_cols = preprocess(df, target_col)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train, X_test = fit_label_encoders(X_train.copy(), X_test.copy(), cat_cols)\n",
    "X_train, X_test = standardize_numeric(X_train, X_test, num_cols)\n",
    "\n",
    "xgb_dist, cat_dist = get_param_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981f8892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "2 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:33:55] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 46) : \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:33:56] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 46) : \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [ -9.16011118 -27.39357678 -12.47169167          nan -26.31784521\n",
      "          nan -26.13478619  -7.58617958]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -7.586179577742712 | Best params: {'subsample': 0.8, 'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "xgb_best = tune_model(\n",
    "    XGBRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1,\n",
    "        objective='reg:squarederror',\n",
    "        verbosity=0,\n",
    "        tree_method='gpu_hist' if GPU_AVAILABLE else 'hist',\n",
    "        predictor='gpu_predictor' if GPU_AVAILABLE else 'auto'\n",
    "    ),\n",
    "    xgb_dist, X_train, y_train, n_iter=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e0989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "cat_best = tune_model(\n",
    "    CatBoostRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=0,\n",
    "        task_type='GPU' if GPU_AVAILABLE else 'CPU',\n",
    "        devices='0' if GPU_AVAILABLE else None\n",
    "    ),\n",
    "    cat_dist, X_train, y_train, n_iter=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee78431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     84878\n",
      "         1.0       1.00      1.00      1.00     26865\n",
      "\n",
      "    accuracy                           1.00    111743\n",
      "   macro avg       1.00      1.00      1.00    111743\n",
      "weighted avg       1.00      1.00      1.00    111743\n",
      "\n",
      "Predicted delay for first flight: [1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"flight_data_2018_2024.csv\", low_memory=False)\n",
    "\n",
    "# Drop unused columns\n",
    "df = df.drop(columns=[\"Unnamed: 119\"], errors=\"ignore\")\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"ArrDel15\"])\n",
    "\n",
    "# Separate features and target\n",
    "y = df[\"ArrDel15\"]\n",
    "X = df.drop(columns=[\"ArrDel15\"])\n",
    "\n",
    "# Fill missing values\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].fillna(\"Unknown\")\n",
    "    else:\n",
    "        X[col] = X[col].fillna(-1)\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example prediction with first row\n",
    "sample = X.iloc[[0]]\n",
    "print(\"Predicted delay for first flight:\", model.predict(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3435a699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     84878\n",
      "         1.0       1.00      1.00      1.00     26865\n",
      "\n",
      "    accuracy                           1.00    111743\n",
      "   macro avg       1.00      1.00      1.00    111743\n",
      "weighted avg       1.00      1.00      1.00    111743\n",
      "\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.944569234761909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96     84878\n",
      "         1.0       0.96      0.80      0.87     26865\n",
      "\n",
      "    accuracy                           0.94    111743\n",
      "   macro avg       0.95      0.90      0.92    111743\n",
      "weighted avg       0.95      0.94      0.94    111743\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     84878\n",
      "         1.0       1.00      1.00      1.00     26865\n",
      "\n",
      "    accuracy                           1.00    111743\n",
      "   macro avg       1.00      1.00      1.00    111743\n",
      "weighted avg       1.00      1.00      1.00    111743\n",
      "\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     84878\n",
      "         1.0       1.00      1.00      1.00     26865\n",
      "\n",
      "    accuracy                           1.00    111743\n",
      "   macro avg       1.00      1.00      1.00    111743\n",
      "weighted avg       1.00      1.00      1.00    111743\n",
      "\n",
      "\n",
      "=== KNN ===\n",
      "Accuracy: 0.7913247362250879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.95      0.87     84878\n",
      "         1.0       0.65      0.29      0.40     26865\n",
      "\n",
      "    accuracy                           0.79    111743\n",
      "   macro avg       0.73      0.62      0.64    111743\n",
      "weighted avg       0.77      0.79      0.76    111743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"flight_data_2018_2024.csv\", low_memory=False)\n",
    "\n",
    "# Drop unused columns\n",
    "df = df.drop(columns=[\"Unnamed: 119\"], errors=\"ignore\")\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"ArrDel15\"])\n",
    "\n",
    "# Separate features and target\n",
    "y = df[\"ArrDel15\"]\n",
    "X = df.drop(columns=[\"ArrDel15\"])\n",
    "\n",
    "# Fill missing values\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].fillna(\"Unknown\")\n",
    "    else:\n",
    "        X[col] = X[col].fillna(-1)\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models to compare\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
